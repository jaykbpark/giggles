# Cursor Rules - Clip (Meta Wearables DAT iOS Project)

> **Project:** Clip (iOS companion app for Meta Ray-Ban glasses)  
> **Platform:** iOS 17.0+ (Swift 5.0+, SwiftUI)  
> **SDK:** Meta Wearables Device Access Toolkit (DAT)  
> **UI Direction:** Warm minimal, timeline-first, Liquid Glass (iOS 26+)

Development progress lives in [`frontend/PROGRESS.md`](frontend/PROGRESS.md).

---

## Table of Contents

1. [Non-Negotiable Workflow](#non-negotiable-workflow)
2. [Meta Wearables DAT SDK](#meta-wearables-dat-sdk)
3. [Architecture Patterns](#architecture-patterns)
4. [Code Style Rules](#code-style-rules)
5. [Common Gotchas & Warnings](#common-gotchas--warnings)
6. [Info.plist Configuration](#infoplist-configuration)
7. [Design Rules (Liquid Glass)](#design-rules-liquid-glass)
8. [File Structure](#file-structure)

---

## Non-Negotiable Workflow

### 1) Pull first, always
```bash
cd /Users/rook/Documents/GitHub/giggles && git pull origin main
git log --oneline -10
```
After pulling, **explicitly say**: "Pulled latest and on `main`."

### 2) Build + run after any code change

> **‚ö†Ô∏è IMPORTANT: Before building, ASK the user if they want Mock Mode ON or OFF.**
> - **Mock Mode ON:** Use when no physical Meta glasses are connected (simulator or device without glasses)
> - **Mock Mode OFF:** Use when physical Meta Ray-Ban glasses are paired and connected
> - If user hasn't specified, **ask before proceeding with the build**

**Simulator with Mock Mode (recommended for simulator):**
```bash
cd /Users/rook/Documents/GitHub/giggles/frontend && \
xcodebuild -project nw2025.xcodeproj -scheme nw2025 \
  -destination 'platform=iOS Simulator,name=iPhone 17 Pro' \
  -configuration Debug build && \
xcrun simctl boot "iPhone 17 Pro" || true && \
xcrun simctl install "iPhone 17 Pro" ~/Library/Developer/Xcode/DerivedData/nw2025-*/Build/Products/Debug-iphonesimulator/nw2025.app && \
SIMCTL_CHILD_USE_MOCK_GLASSES=1 xcrun simctl launch "iPhone 17 Pro" me.park.jay.nw2025
```

**Simulator without Mock Mode (real SDK):**
```bash
cd /Users/rook/Documents/GitHub/giggles/frontend && \
xcodebuild -project nw2025.xcodeproj -scheme nw2025 \
  -destination 'platform=iOS Simulator,name=iPhone 17 Pro' \
  -configuration Debug build && \
xcrun simctl boot "iPhone 17 Pro" || true && \
xcrun simctl install "iPhone 17 Pro" ~/Library/Developer/Xcode/DerivedData/nw2025-*/Build/Products/Debug-iphonesimulator/nw2025.app && \
xcrun simctl launch "iPhone 17 Pro" me.park.jay.nw2025
```

**Device with Mock Mode:**
```bash
cd /Users/rook/Documents/GitHub/giggles/frontend && \
xcodebuild -project nw2025.xcodeproj -scheme nw2025 \
  -destination 'id=00008140-001534E83647001C' \
  -configuration Debug -allowProvisioningUpdates build && \
xcrun devicectl device install app --device 00008140-001534E83647001C \
  ~/Library/Developer/Xcode/DerivedData/nw2025-*/Build/Products/Debug-iphoneos/nw2025.app && \
xcrun devicectl device process launch --device 00008140-001534E83647001C \
  --environment USE_MOCK_GLASSES=1 me.park.jay.nw2025
```

**Device without Mock Mode (real glasses connected):**
```bash
cd /Users/rook/Documents/GitHub/giggles/frontend && \
xcodebuild -project nw2025.xcodeproj -scheme nw2025 \
  -destination 'id=00008140-001534E83647001C' \
  -configuration Debug -allowProvisioningUpdates build && \
xcrun devicectl device install app --device 00008140-001534E83647001C \
  ~/Library/Developer/Xcode/DerivedData/nw2025-*/Build/Products/Debug-iphoneos/nw2025.app && \
xcrun devicectl device process launch --device 00008140-001534E83647001C me.park.jay.nw2025
```

If build/run fails, **stop and report the error**.

### 3) Commit/push only after user confirms it works
```bash
git add -A
git commit -m "<type>: <summary>"
git push origin main
```

Commit types: `Feat`, `Fix`, `UI`, `Refactor`, `Chore`.

After pushing, **explicitly say**: branch + commit hash + summary.

---

## Meta Wearables DAT SDK

**SPM URL:** `https://github.com/facebook/meta-wearables-dat-ios`  
**Docs:** `https://wearables.developer.meta.com/docs/develop`

### SDK Imports

```swift
import MWDATCore    // Core SDK: Wearables, registration, permissions, device management
import MWDATCamera  // Camera/streaming: StreamSession, VideoFrame, PhotoData

#if DEBUG
import MWDATMockDevice  // Debug-only mock device simulation (MockDeviceKit)
#endif
```

### 1. SDK Initialization (REQUIRED)

Call `Wearables.configure()` **once** at app startup in the `@main` App struct:

```swift
@main
struct ClipApp: App {
    init() {
        do {
            try Wearables.configure()
        } catch {
            #if DEBUG
            print("[SDK] Configuration failed: \(error)")
            #endif
        }
    }
    
    var body: some Scene {
        WindowGroup {
            ContentView()
        }
    }
}
```

**Rules:**
- Call ONLY ONCE at app launch
- Use `Wearables.shared` singleton for all subsequent SDK access
- Wrap in do-catch and log errors in DEBUG builds
- NEVER call `configure()` multiple times

### 2. Registration Flow & Deep Links

Registration is an OAuth-like flow with the Meta AI app. Track state via `RegistrationState` enum:
- `.available` - SDK available, not yet registered
- `.registering` - Registration in progress
- `.registered` - Successfully registered with Meta AI app
- `.unavailable` - SDK not available

```swift
// Start registration (opens Meta AI app for OAuth)
try wearables.startRegistration()

// Handle callback URL via SwiftUI .onOpenURL
.onOpenURL { url in
    // Check for metaWearablesAction query parameter BEFORE processing
    if url.absoluteString.contains("metaWearablesAction") {
        Task {
            let handled = try await Wearables.shared.handleUrl(url)
        }
    }
}

// PREFERRED: Use AsyncSequence for registration state changes
func observeRegistration() {
    registrationTask = Task {
        for await state in wearables.registrationStateStream() {
            await MainActor.run {
                switch state {
                case .registered:
                    // Proceed to device detection
                case .registering:
                    // Show loading state
                case .available, .unavailable:
                    // Handle accordingly
                @unknown default:
                    break
                }
            }
        }
    }
}

// Alternative: Listener-based approach
let token = wearables.addRegistrationStateListener { state in
    Task { @MainActor in
        // Handle state changes
    }
}
```

### 3. Device Management

**CRITICAL:** Only listen for devices AFTER registration completes.

```swift
// PREFERRED: Use AsyncSequence for device detection
func observeDevices() {
    deviceTask = Task {
        for await devices in wearables.devicesStream() {
            // Process device list
            if let firstDevice = devices.first,
               let device = wearables.deviceForIdentifier(firstDevice) {
                await connectToDevice(device)
            }
        }
    }
}

// Or use manual device checking
let deviceIds = wearables.devices  // Returns [DeviceIdentifier]
if let deviceId = deviceIds.first,
   let device = wearables.deviceForIdentifier(deviceId) {
    // Use device
}

// Check device compatibility before streaming
let compatibilityToken = device.addCompatibilityListener { compatibility in
    Task { @MainActor in
        // Check if device supports required features
    }
}

// Monitor device link state
let linkToken = device.addLinkStateListener { linkState in
    switch linkState {
    case .connected:    // Ready for streaming
    case .connecting:   // Connection in progress
    case .disconnected: // Not connected
    @unknown default: break
    }
}
```

### 4. Streaming Architecture

#### AutoDeviceSelector (Recommended)
Use `AutoDeviceSelector` for automatic device selection and management:

```swift
// Create auto device selector
let deviceSelector = AutoDeviceSelector(wearables: wearables)

// Track active device with AsyncSequence
func observeActiveDevice() {
    activeDeviceTask = Task {
        for await device in deviceSelector.activeDeviceStream() {
            await MainActor.run {
                // Handle active device changes
                self.activeDevice = device
            }
        }
    }
}
```

#### StreamSession Configuration

```swift
// Create stream session with configuration
let config = StreamSessionConfig(
    videoCodec: .raw,      // or .h264
    resolution: .low,      // .low, .medium, .high (start with .low for stability)
    frameRate: 24          // 24 fps recommended for smooth streaming
)

// Use AutoDeviceSelector with StreamSession (recommended)
let session = StreamSession(
    streamSessionConfig: config,
    deviceSelector: deviceSelector  // AutoDeviceSelector instance
)

// Or use SpecificDeviceSelector for a specific device
let specificSelector = SpecificDeviceSelector(device: device.identifier)
let session = StreamSession(
    streamSessionConfig: config,
    deviceSelector: specificSelector
)
```

### 5. Event Subscription Pattern (Listener Tokens)

**CRITICAL:** All SDK events use a publisher-listener pattern. ALWAYS retain listener tokens (`AnyListenerToken`) as properties.

```swift
@MainActor
class StreamViewModel: ObservableObject {
    // ALWAYS store tokens as properties - they are released when deallocated
    private var streamStateToken: (any AnyListenerToken)?
    private var videoFrameToken: (any AnyListenerToken)?
    private var errorToken: (any AnyListenerToken)?
    private var photoToken: (any AnyListenerToken)?
    
    @Published var currentVideoFrame: UIImage?
    @Published var isStreaming = false
    private var hasReceivedFirstFrame = false
    
    func setupListeners(session: StreamSession) {
        // Session state listener
        streamStateToken = session.statePublisher.listen { [weak self] state in
            Task { @MainActor in
                guard let self else { return }
                switch state {
                case .stopped:
                    self.isStreaming = false
                case .waitingForDevice:
                    // Waiting for device connection
                    break
                case .starting:
                    // Initializing stream
                    break
                case .streaming:
                    self.isStreaming = true
                case .stopping:
                    // Shutting down
                    break
                case .paused:
                    // Temporarily paused
                    break
                @unknown default:
                    break
                }
            }
        }
        
        // Video frame listener
        videoFrameToken = session.videoFramePublisher.listen { [weak self] frame in
            Task { @MainActor in
                guard let self else { return }
                // Convert VideoFrame to UIImage
                self.currentVideoFrame = frame.makeUIImage()
                
                // Track first frame for loading states
                if !self.hasReceivedFirstFrame {
                    self.hasReceivedFirstFrame = true
                }
            }
        }
        
        // Error listener
        errorToken = session.errorPublisher.listen { [weak self] error in
            Task { @MainActor in
                guard let self else { return }
                self.handleStreamError(error)
            }
        }
        
        // Photo capture listener
        photoToken = session.photoDataPublisher.listen { [weak self] photoData in
            Task { @MainActor in
                guard let self else { return }
                // Convert to UIImage
                if let image = UIImage(data: photoData.data) {
                    self.handleCapturedPhoto(image)
                }
            }
        }
    }
}
```

### 6. Session States

Handle `StreamSessionState` enum properly:

| State | Description |
|-------|-------------|
| `.stopped` | Not streaming |
| `.waitingForDevice` | Waiting for device connection |
| `.starting` | Initializing stream |
| `.streaming` | Actively receiving frames |
| `.stopping` | Shutting down |
| `.paused` | Temporarily paused |

### 7. Photo Capture

```swift
// Trigger photo capture
streamSession.capturePhoto(format: .jpeg)  // or .heic

// Receive via photoDataPublisher listener
photoToken = session.photoDataPublisher.listen { photoData in
    Task { @MainActor in
        if let image = UIImage(data: photoData.data) {
            // Use captured photo
        }
    }
}
```

### 8. Permission Handling

```swift
// Check permission status
let status = try await wearables.checkPermissionStatus(.camera)

// Request permission if needed
let granted = try await wearables.requestPermission(.camera)

// Permission status enum
switch status {
case .granted:
    // Ready to stream
case .denied:
    // Show permission denied UI
default:
    break
}

// ALWAYS check/request camera permission before starting stream
guard try await wearables.requestPermission(.camera) == .granted else {
    throw GlassesError.permissionDenied
}
await session.start()
```

### 9. Starting & Stopping Streams

```swift
// Start the session (always after setting up listeners and checking permissions)
await session.start()

// Stop when done
await session.stop()
```

### 10. Mock Mode Implementation

```swift
@MainActor
final class MetaGlassesManager: ObservableObject {
    static let shared = MetaGlassesManager()
    
    private let provider: GlassesStreamProvider
    let isMockMode: Bool
    
    init() {
        // Check for USE_MOCK_GLASSES environment variable
        let useMock = ProcessInfo.processInfo.environment["USE_MOCK_GLASSES"] != nil
        self.isMockMode = useMock
        
        if useMock {
            self.provider = MockGlassesProvider()
            print("üï∂Ô∏è MetaGlassesManager: Using MOCK provider")
        } else {
            self.provider = MetaSDKProvider()
            print("üï∂Ô∏è MetaGlassesManager: Using REAL SDK provider")
        }
    }
}
```

### 11. Testing with MWDATMockDevice

```swift
#if DEBUG
import MWDATMockDevice

// MockDeviceKit.shared manages mock devices
func setupMockDevice() {
    // Create simulated Ray-Ban Meta glasses
    MockDeviceKit.shared.pairRaybanMeta()
    // Mock devices support full streaming workflow
}
#endif
```

**Mock Mode Activation:**
- Environment Variable: `USE_MOCK_GLASSES=1`
- Simulator: Use `SIMCTL_CHILD_USE_MOCK_GLASSES=1` prefix before `xcrun simctl launch`

---

## Architecture Patterns

### ViewModel Pattern (REQUIRED)

```swift
@MainActor
final class StreamSessionViewModel: ObservableObject {
    // Published properties for reactive UI
    @Published private(set) var connectionState: ConnectionState = .disconnected
    @Published private(set) var isStreaming = false
    @Published private(set) var currentFrame: UIImage?
    @Published var errorMessage: String?
    
    // Store Task references for async streams
    private var deviceTask: Task<Void, Never>?
    private var streamTask: Task<Void, Never>?
    
    // Store listener tokens for SDK listeners
    private var linkStateToken: (any AnyListenerToken)?
    private var videoFrameToken: (any AnyListenerToken)?
    private var streamStateToken: (any AnyListenerToken)?
    
    // Dependency injection for testability
    private let wearables: any WearablesInterface
    
    init(wearables: any WearablesInterface = Wearables.shared) {
        self.wearables = wearables
    }
    
    deinit {
        // CRITICAL: Cancel all Tasks and tokens
        deviceTask?.cancel()
        streamTask?.cancel()
        
        Task {
            await linkStateToken?.cancel()
            await videoFrameToken?.cancel()
            await streamStateToken?.cancel()
        }
    }
}
```

### Error Handling Pattern

```swift
// Registration errors
do {
    try wearables.startRegistration()
} catch let error as RegistrationError {
    switch error {
    case .metaAIAppNotInstalled:
        showError("Please install the Meta AI app")
    case .developerModeNotEnabled:
        showError("Enable Developer Mode in Meta AI app")
    default:
        showError("Registration failed: \(error.localizedDescription)")
    }
}

// Streaming errors (handle all cases from SDK)
// StreamSessionError cases:
//   .internalError       - Internal SDK error
//   .deviceNotFound      - Device unavailable
//   .deviceNotConnected  - Connection lost
//   .timeout             - Operation timed out
//   .videoStreamingError - Video streaming failure
//   .audioStreamingError - Audio streaming failure
//   .permissionDenied    - Camera permission denied

func handleStreamError(_ error: StreamSessionError) {
    switch error {
    case .internalError:
        showError("Internal error occurred")
    case .deviceNotFound:
        showError("Device not found")
    case .deviceNotConnected:
        showError("Device disconnected")
    case .timeout:
        showError("Connection timed out")
    case .videoStreamingError:
        showError("Video streaming error")
    case .audioStreamingError:
        showError("Audio streaming error")
    case .permissionDenied:
        showError("Camera permission denied")
    @unknown default:
        showError("Unknown error")
    }
}

// Custom app error type
enum GlassesError: Error, LocalizedError {
    case sdkNotAvailable
    case deviceNotFound
    case notConnected
    case permissionDenied
    case connectionFailed(String)
    case streamFailed(String)
    case audioNotSupported
    
    var errorDescription: String? {
        switch self {
        case .sdkNotAvailable:
            return "Meta SDK is not available"
        case .deviceNotFound:
            return "No glasses found. Make sure they're paired in Meta AI app"
        case .notConnected:
            return "Glasses not connected"
        case .permissionDenied:
            return "Camera permission denied"
        case .connectionFailed(let msg):
            return "Connection failed: \(msg)"
        case .streamFailed(let msg):
            return "Stream failed: \(msg)"
        case .audioNotSupported:
            return "Audio streaming not yet supported by SDK"
        }
    }
}
```

---

## Code Style Rules

### 1. Use SwiftUI for All Views
```swift
// GOOD
struct StreamView: View {
    @StateObject private var viewModel = StreamSessionViewModel()
    
    var body: some View {
        // View content
    }
}

// BAD - Don't use UIKit views unless absolutely necessary
class StreamViewController: UIViewController { }
```

### 2. MVVM Separation
- Views: Display only, no business logic
- ViewModels: All SDK interaction, state management, business logic
- Models: Data structures only

### 3. Dependency Injection for Testability
```swift
// GOOD - Protocol-based injection
protocol WearablesInterface {
    var registrationState: RegistrationState { get }
    var devices: [DeviceIdentifier] { get }
    func startRegistration() throws
}

class ViewModel {
    private let wearables: any WearablesInterface
    
    init(wearables: any WearablesInterface = Wearables.shared) {
        self.wearables = wearables
    }
}

// BAD - Direct singleton access everywhere
class ViewModel {
    func connect() {
        Wearables.shared.startRegistration() // Hard to test
    }
}
```

### 4. Wrap Mock Imports in DEBUG
```swift
// GOOD
#if DEBUG
import MWDATMockDevice

func setupMockDevice() {
    MockDeviceKit.enable()
}
#endif

// BAD - Mock code in release builds
import MWDATMockDevice // Will fail in production
```

### 5. MainActor for UI Updates
```swift
// GOOD - Listener callbacks dispatched to MainActor
videoFrameToken = session.videoFramePublisher.listen { frame in
    Task { @MainActor in
        self.currentFrame = frame.makeUIImage()
    }
}

// BAD - UI updates from background
videoFrameToken = session.videoFramePublisher.listen { frame in
    self.currentFrame = frame.makeUIImage() // Crash risk
}
```

### 6. Proper Resource Cleanup
```swift
// GOOD - Always clean up in deinit
deinit {
    deviceTask?.cancel()
    
    Task {
        await videoFrameToken?.cancel()
        await streamSession?.stop()
    }
}

// BAD - Leaking resources
deinit {
    // Nothing here = memory leaks and zombie listeners
}
```

---

## Common Gotchas & Warnings

### ‚ö†Ô∏è Critical Issues

1. **Registration MUST complete before devices appear**
   ```swift
   // WRONG - Checking devices before registration
   let devices = wearables.devices // Always empty!
   
   // RIGHT - Wait for .registered state first
   if wearables.registrationState == .registered {
       let devices = wearables.devices
   }
   ```

2. **Meta AI app must have Developer Mode enabled**
   - Open Meta AI app ‚Üí Settings ‚Üí Developer Mode ‚Üí Enable
   - Required for `MetaAppID` of "0" during development

3. **Glasses must be paired in Meta AI app FIRST**
   - The DAT SDK cannot pair glasses directly
   - User must complete pairing in Meta AI app before your app can detect them

4. **URL scheme MUST match Meta Developer Portal**
   - Info.plist `AppLinkURLScheme` must exactly match what's registered
   - Mismatch = OAuth callbacks silently fail

5. **Audio streaming NOT supported**
   ```swift
   // The Meta DAT SDK does NOT support microphone streaming from glasses
   // Use iPhone microphone for wake word detection instead
   try await provider.startAudioStream() // Will throw GlassesError.audioNotSupported
   ```

### ‚ö° Performance Issues

1. **Cancel Tasks in deinit**
   - Uncancelled Tasks cause memory leaks
   - Zombie listeners keep receiving callbacks

2. **Don't call configure() multiple times**
   - SDK initialization is expensive
   - Multiple calls cause undefined behavior

3. **Use weak self in listeners**
   ```swift
   token = publisher.listen { [weak self] value in
       guard let self else { return }
       // Use self
   }
   ```

### üîß Debugging Tips

1. **Check registration state first** when devices aren't appearing
2. **Enable verbose logging** in DEBUG builds
3. **Use mock mode** when glasses aren't available
4. **Console output** `üï∂Ô∏è MetaGlassesManager: Using MOCK provider` confirms mock mode

---

## Info.plist Configuration

**REQUIRED** keys for Meta Wearables DAT SDK:

```xml
<!-- Meta Wearables SDK Configuration -->
<key>MWDAT</key>
<dict>
    <key>AppLinkURLScheme</key>
    <string>clipapp://</string>
    <key>MetaAppID</key>
    <string>YOUR_META_APP_ID</string>
    <key>ClientToken</key>
    <string>YOUR_CLIENT_TOKEN</string>
    <key>TeamID</key>
    <string>YOUR_APPLE_TEAM_ID</string>
    <!-- Optional: Opt out of analytics -->
    <key>Analytics</key>
    <dict>
        <key>OptOut</key>
        <true/>
    </dict>
</dict>

<!-- Background Modes for Bluetooth -->
<key>UIBackgroundModes</key>
<array>
    <string>bluetooth-peripheral</string>
    <string>external-accessory</string>
</array>

<!-- Bluetooth Permission -->
<key>NSBluetoothAlwaysUsageDescription</key>
<string>Needed to connect to Meta AI Glasses</string>

<!-- External Accessory Protocol -->
<key>UISupportedExternalAccessoryProtocols</key>
<array>
    <string>com.meta.ar.wearable</string>
</array>

<!-- URL Schemes to Query -->
<key>LSApplicationQueriesSchemes</key>
<array>
    <string>fb-viewapp</string>
</array>

<!-- Camera Permission (for photo capture) -->
<key>NSCameraUsageDescription</key>
<string>Required to capture photos from glasses</string>

<!-- Microphone Permission (for iPhone-based wake word) -->
<key>NSMicrophoneUsageDescription</key>
<string>Required for voice commands</string>

<!-- Location Permission (required for BLE scanning on iOS) -->
<key>NSLocationWhenInUseUsageDescription</key>
<string>Required to discover nearby glasses via Bluetooth</string>
```

---

## Design Rules (Liquid Glass)

For iOS 26+ Liquid Glass UI:

- Use `.glassEffect()` for chrome and controls
- Use `.glassEffect(.regular.interactive())` for tappable elements
- Avoid glass on primary content blocks (transcripts, timeline cards)
- Warm off-white background, soft surfaces, subtle shadows
- Generous spacing; avoid visual noise

**Docs:**  
`/Applications/Xcode.app/Contents/PlugIns/IDEIntelligenceChat.framework/Versions/A/Resources/AdditionalDocumentation/`

---

## File Structure

```
ClipApp/
‚îú‚îÄ‚îÄ App/
‚îÇ   ‚îú‚îÄ‚îÄ ClipApp.swift              # @main entry, SDK configuration
‚îÇ   ‚îî‚îÄ‚îÄ GlobalViewState.swift      # App-wide state
‚îú‚îÄ‚îÄ Core/
‚îÇ   ‚îú‚îÄ‚îÄ DesignSystem/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Colors.swift
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Gradients.swift
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Typography.swift
‚îÇ   ‚îú‚îÄ‚îÄ Managers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MetaGlasses/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MetaGlassesManager.swift    # Unified interface
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ GlassesStreamProvider.swift # Protocol
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MetaSDKProvider.swift       # Real SDK wrapper
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MockGlassesProvider.swift   # Mock for testing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ WakeWordDetector.swift
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CameraManager.swift
‚îÇ   ‚îî‚îÄ‚îÄ Navigation/
‚îÇ       ‚îî‚îÄ‚îÄ RootView.swift
‚îú‚îÄ‚îÄ Features/
‚îÇ   ‚îî‚îÄ‚îÄ Feed/
‚îÇ       ‚îú‚îÄ‚îÄ TimelineView.swift
‚îÇ       ‚îú‚îÄ‚îÄ MomentCard.swift
‚îÇ       ‚îî‚îÄ‚îÄ ClipDetailView.swift
‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îú‚îÄ‚îÄ ClipMetadata.swift
‚îÇ   ‚îî‚îÄ‚îÄ SearchResult.swift
‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îú‚îÄ‚îÄ APIService.swift
‚îÇ   ‚îî‚îÄ‚îÄ MockData.swift
‚îî‚îÄ‚îÄ Info.plist                      # REQUIRED MWDAT keys
```

---

## Wake Word Integration

Location: `Core/Managers/WakeWordDetector.swift`

```swift
// Wake word uses iPhone microphone (NOT glasses microphone)
wakeWordDetector.startListening(audioFormat: format)
wakeWordDetector.processAudioBuffer(buffer)
wakeWordDetector.onClipTriggered = { transcript in
    // Trigger 30s video capture
}
```

**Notes:**
- On-device recognition
- 30s rolling transcript buffer
- Auto restart every 50s
- Uses iPhone mic since glasses audio not supported by SDK

---

## Quick Reference

| Task | Pattern |
|------|---------|
| Initialize SDK | `try Wearables.configure()` once in `@main` |
| Get SDK instance | `Wearables.shared` |
| Start registration | `try wearables.startRegistration()` |
| Handle OAuth callback | `try await wearables.handleUrl(url)` |
| Check registration | `wearables.registrationState == .registered` |
| Registration stream | `for await state in wearables.registrationStateStream()` |
| Devices stream | `for await devices in wearables.devicesStream()` |
| Get device object | `wearables.deviceForIdentifier(id)` |
| Auto device selector | `AutoDeviceSelector(wearables: wearables)` |
| Active device stream | `for await device in deviceSelector.activeDeviceStream()` |
| Stream config | `StreamSessionConfig(videoCodec: .raw, resolution: .low, frameRate: 24)` |
| Create session | `StreamSession(streamSessionConfig: config, deviceSelector: selector)` |
| Video frames | `session.videoFramePublisher.listen { frame in }` |
| Session state | `session.statePublisher.listen { state in }` |
| Stream errors | `session.errorPublisher.listen { error in }` |
| Photo capture | `session.capturePhoto(format: .jpeg)` |
| Photo listener | `session.photoDataPublisher.listen { photo in }` |
| Frame to UIImage | `videoFrame.makeUIImage()` |
| Check permission | `try await wearables.checkPermissionStatus(.camera)` |
| Request permission | `try await wearables.requestPermission(.camera)` |
| Start stream | `await session.start()` |
| Stop stream | `await session.stop()` |
| Check mock mode | `ProcessInfo.processInfo.environment["USE_MOCK_GLASSES"] != nil` |
| Setup mock device | `MockDeviceKit.shared.pairRaybanMeta()` (DEBUG only) |
